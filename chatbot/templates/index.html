<!DOCTYPE html>
<html>
<head>
  <title>Voice Chatbot</title>
  <style>
    body { font-family: Arial, sans-serif; text-align: center; margin-top: 40px; }
    #messages { margin: 18px auto; max-width: 720px; text-align: left; }
    #messages p { margin: 8px 0; }
    #mic-btn {
      background-color: #4CAF50; border: none; border-radius: 999px;
      width: 120px; height: 56px; font-size: 18px; color: white; cursor: pointer;
      box-shadow: 0 6px 16px rgba(0,0,0,.15);
    }
    #mic-btn.stopped { background:#ff4b5c; }
    audio { display:none; }
  </style>
</head>
<body>
  <h1>üéôÔ∏è Voice Chatbot (AEC enabled)</h1>
  <button id="mic-btn">Start</button>
  <div id="messages"></div>

  <script>
    const messagesDiv = document.getElementById("messages");
    const micBtn = document.getElementById("mic-btn");

    let pc;
    let dc;              // DataChannel for events/messages
    let localStream;

    function addMsg(prefix, text) {
      const p = document.createElement("p");
      p.textContent = `${prefix} ${text}`;
      messagesDiv.appendChild(p);
      messagesDiv.scrollTop = messagesDiv.scrollHeight;
    }

    async function getUserAudioStream() {
      // ‚úÖ WebRTC audio processing (echoCancellation / noiseSuppression / AGC)
      return await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
    }

    async function startWebRTC() {
      pc = new RTCPeerConnection({
        iceServers: [{ urls: "stun:stun.l.google.com:19302" }],
      });

      // 1) Add mic (sendonly) with AEC
      localStream = await getUserAudioStream();
      const [micTrack] = localStream.getAudioTracks();
      pc.addTrack(micTrack, localStream);

      // 2) Bot audio (recvonly)
      pc.addTransceiver("audio", { direction: "recvonly" });

      // play bot audio
      pc.ontrack = (event) => {
        const audio = document.createElement("audio");
        audio.autoplay = true;
        audio.srcObject = event.streams[0];
        document.body.appendChild(audio);
      };

      // 3) Events channel (client-initiated)
      dc = pc.createDataChannel("events");
      dc.onopen = () => addMsg("‚ÑπÔ∏è", "Channel open");
      dc.onmessage = (e) => {
        try {
          const msg = JSON.parse(e.data);
          if (msg.user_text) addMsg("üßë", msg.user_text);
          if (msg.bot_text)  addMsg("ü§ñ", msg.bot_text);
          if (msg.info)      addMsg("‚ÑπÔ∏è", msg.info);
        } catch {
          addMsg("‚ÑπÔ∏è", String(e.data));
        }
      };

      // create offer
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      // send to server
      const resp = await fetch("/webrtc/offer", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          sdp: pc.localDescription.sdp,
          type: pc.localDescription.type
        })
      });
      const answer = await resp.json();
      await pc.setRemoteDescription(answer);
    }

    micBtn.addEventListener("click", async () => {
      micBtn.disabled = true;
      try {
        await startWebRTC();
        micBtn.textContent = "Running";
        micBtn.classList.remove("stopped");
      } catch (e) {
        console.error(e);
        micBtn.textContent = "Error";
        micBtn.classList.add("stopped");
      } finally {
        micBtn.disabled = false;
      }
    });
  </script>
</body>
</html>
